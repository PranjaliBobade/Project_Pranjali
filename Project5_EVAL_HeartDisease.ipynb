{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Read data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data using pandas\n",
    "df=pd.read_csv(\"F:/Pranjali/Data Science/Eval Project/Data Files/heartDisease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>132.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>142.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0   63    1   4     140.0  260.0    0        1    112.0    1.0      3.0   \n",
       "1   44    1   4     130.0  209.0    0        1    127.0    0.0      0.0   \n",
       "2   60    1   4     132.0  218.0    0        1    140.0    1.0      1.5   \n",
       "3   55    1   4     142.0  228.0    0        1    149.0    1.0      2.5   \n",
       "4   66    1   3     110.0  213.0    1        2     99.0    1.0      1.3   \n",
       "\n",
       "   slope  ca  thal  num  \n",
       "0    2.0 NaN   NaN    2  \n",
       "1    NaN NaN   NaN    4  \n",
       "2    3.0 NaN   NaN    2  \n",
       "3    1.0 NaN   NaN    1  \n",
       "4    2.0 NaN   NaN    4  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       200 non-null    int64  \n",
      " 1   sex       200 non-null    int64  \n",
      " 2   cp        200 non-null    int64  \n",
      " 3   trestbps  144 non-null    float64\n",
      " 4   chol      193 non-null    float64\n",
      " 5   fbs       200 non-null    int64  \n",
      " 6   restecg   200 non-null    int64  \n",
      " 7   thalach   147 non-null    float64\n",
      " 8   exang     147 non-null    float64\n",
      " 9   oldpeak   144 non-null    float64\n",
      " 10  slope     98 non-null     float64\n",
      " 11  ca        2 non-null      float64\n",
      " 12  thal      34 non-null     float64\n",
      " 13  num       200 non-null    int64  \n",
      "dtypes: float64(8), int64(6)\n",
      "memory usage: 22.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Converion in required datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['trestbps'] = le.fit_transform(df.trestbps.values)\n",
    "df['trestbps'] = df['trestbps'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['chol'] = le.fit_transform(df.chol.values)\n",
    "df['chol'] = df['chol'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['thalach'] = le.fit_transform(df.thalach.values)\n",
    "df['thalach'] = df['thalach'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['exang'] = le.fit_transform(df.exang.values)\n",
    "df['exang'] = df['exang'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['oldpeak'] = le.fit_transform(df.oldpeak.values)\n",
    "df['oldpeak'] = df['oldpeak'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['slope'] = le.fit_transform(df.slope.values)\n",
    "df['slope'] = df['slope'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['ca'] = le.fit_transform(df.ca.values)\n",
    "df['ca'] = df['ca'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['thal'] = le.fit_transform(df.thal.values)\n",
    "df['thal'] = df['thal'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing NaN Values-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing NaN values\n",
    "import numpy as np\n",
    "\n",
    "df['trestbps'].replace(np.NaN,df['trestbps'].mean,inplace=True)\n",
    "df['chol'].replace(np.NaN,df['chol'].mean,inplace=True)\n",
    "df['thalach'].replace(np.NaN,df['thalach'].mean,inplace=True)\n",
    "df['exang'].replace(np.NaN,df['exang'].mean,inplace=True)\n",
    "df['oldpeak'].replace(np.NaN,df['oldpeak'].mean,inplace=True)\n",
    "df['slope'].replace(np.NaN,df['slope'].mean,inplace=True)\n",
    "df['ca'].replace(np.NaN,df['ca'].mean,inplace=True)\n",
    "df['thal'].replace(np.NaN,df['thal'].mean,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Data Analysis-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   age       200 non-null    int64\n",
      " 1   sex       200 non-null    int64\n",
      " 2   cp        200 non-null    int64\n",
      " 3   trestbps  200 non-null    int64\n",
      " 4   chol      200 non-null    int64\n",
      " 5   fbs       200 non-null    int64\n",
      " 6   restecg   200 non-null    int64\n",
      " 7   thalach   200 non-null    int64\n",
      " 8   exang     200 non-null    int64\n",
      " 9   oldpeak   200 non-null    int64\n",
      " 10  slope     200 non-null    int64\n",
      " 11  ca        200 non-null    int64\n",
      " 12  thal      200 non-null    int64\n",
      " 13  num       200 non-null    int64\n",
      "dtypes: int64(14)\n",
      "memory usage: 22.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 14)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>59.350000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>3.505000</td>\n",
       "      <td>32.980000</td>\n",
       "      <td>37.760000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>43.530000</td>\n",
       "      <td>7.895000</td>\n",
       "      <td>15.630000</td>\n",
       "      <td>27.840000</td>\n",
       "      <td>98.505000</td>\n",
       "      <td>71.225000</td>\n",
       "      <td>2.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.811697</td>\n",
       "      <td>0.171015</td>\n",
       "      <td>0.795701</td>\n",
       "      <td>24.608688</td>\n",
       "      <td>32.442952</td>\n",
       "      <td>0.474898</td>\n",
       "      <td>0.683455</td>\n",
       "      <td>29.245609</td>\n",
       "      <td>14.455406</td>\n",
       "      <td>18.596296</td>\n",
       "      <td>33.664833</td>\n",
       "      <td>57.870588</td>\n",
       "      <td>53.994922</td>\n",
       "      <td>1.193955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.750000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.250000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>148.250000</td>\n",
       "      <td>118.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  200.000000  200.000000  200.000000  200.000000  200.000000  200.000000   \n",
       "mean    59.350000    0.970000    3.505000   32.980000   37.760000    0.340000   \n",
       "std      7.811697    0.171015    0.795701   24.608688   32.442952    0.474898   \n",
       "min     35.000000    0.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "25%     55.000000    1.000000    3.000000   14.750000    1.750000    0.000000   \n",
       "50%     60.000000    1.000000    4.000000   25.000000   34.500000    0.000000   \n",
       "75%     64.000000    1.000000    4.000000   45.250000   62.250000    1.000000   \n",
       "max     77.000000    1.000000    4.000000   95.000000  105.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  200.000000  200.000000  200.000000  200.000000  200.000000  200.000000   \n",
       "mean     0.735000   43.530000    7.895000   15.630000   27.840000   98.505000   \n",
       "std      0.683455   29.245609   14.455406   18.596296   33.664833   57.870588   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   20.000000    0.000000    4.000000    1.000000   48.750000   \n",
       "50%      1.000000   36.500000    1.000000    9.000000    4.500000   98.500000   \n",
       "75%      1.000000   61.250000    4.250000   19.250000   54.250000  148.250000   \n",
       "max      2.000000  111.000000   54.000000   69.000000  104.000000  198.000000   \n",
       "\n",
       "             thal         num  \n",
       "count  200.000000  200.000000  \n",
       "mean    71.225000    2.540000  \n",
       "std     53.994922    1.193955  \n",
       "min      0.000000    1.000000  \n",
       "25%     18.750000    1.000000  \n",
       "50%     68.500000    3.000000  \n",
       "75%    118.250000    4.000000  \n",
       "max    168.000000    4.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        -0.404091\n",
       "sex        -5.552105\n",
       "cp         -1.648734\n",
       "trestbps    1.005419\n",
       "chol        0.383570\n",
       "fbs         0.680636\n",
       "restecg     0.391463\n",
       "thalach     0.682403\n",
       "exang       1.885461\n",
       "oldpeak     1.495948\n",
       "slope       0.886043\n",
       "ca          0.000508\n",
       "thal        0.170664\n",
       "num        -0.050861\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for skewness : \n",
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 14)\n",
      "(183, 14)\n"
     ]
    }
   ],
   "source": [
    "# Check for the outliers by applying zscore\n",
    "from scipy.stats import zscore\n",
    "z_score=abs(zscore(df))\n",
    "print(df.shape)\n",
    "df_final=df.loc[(z_score<3).all(axis=1)]\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating target & input variables\n",
    "import numpy as np\n",
    "df_x=df_final.drop(columns=[\"num\"])\n",
    "y=df_final[[\"num\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalling the input variable\n",
    "# linear regression algorith requires all feature to be on common scale\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(df_x)\n",
    "x = pd.DataFrame(x,columns=df_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        -0.315096\n",
       "sex         0.000000\n",
       "cp         -1.351565\n",
       "trestbps    1.080181\n",
       "chol        0.409505\n",
       "fbs         0.739427\n",
       "restecg     0.374909\n",
       "thalach     0.772000\n",
       "exang       2.012110\n",
       "oldpeak     1.585330\n",
       "slope       0.958164\n",
       "ca         -0.002783\n",
       "thal        0.151047\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets again check for skewness as its reduced now\n",
    "x.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>67</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>69</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "      <td>100</td>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>198</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "190   51    0   4         8    61    1        2        8      0        4   \n",
       "191   62    1   4        34    59    1        1       17      1       11   \n",
       "192   53    1   4        26    83    1        1       34      1        6   \n",
       "193   62    1   4        33     9    0        1       41      1        1   \n",
       "194   46    1   4        20    87    0        0       32      0        1   \n",
       "195   54    0   4        16    91    1        1       50      0        1   \n",
       "196   62    1   1        63     2    0        1       72      7       36   \n",
       "197   55    1   4        12    40    1        1       12      0        1   \n",
       "198   58    1   4        54    97    1        2       64     32       56   \n",
       "199   62    1   2        11    59    0        2        6      1        1   \n",
       "\n",
       "     slope   ca  thal  num  \n",
       "190      0   64    48    4  \n",
       "191      1   65    49    4  \n",
       "192      1   66    50    3  \n",
       "193     30   67    51    1  \n",
       "194     29   68     0    2  \n",
       "195     28   69    52    1  \n",
       "196     27   70    53    4  \n",
       "197     26   71     1    2  \n",
       "198     68  100   139    4  \n",
       "199    104  198   168    1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b025480088>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking correlation\n",
    "dfcor=df.corr()\n",
    "sns.heatmap(dfcor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Logistic Regression Algorithm as target is categorical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.get_dummies(df)\n",
    "\n",
    "feature_cols = ['thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
    "\n",
    "X = data[feature_cols]\n",
    "\n",
    "y = data.num  # y is a vector, hence we use dot to access 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(200, 6)\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()        # instantiate model\n",
    "logreg.fit(X_train, y_train)         # fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "# make class predictions for the testing set\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "\n",
    "# Classification accuracy: percentage of correct predictions\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    17\n",
       "1    16\n",
       "3    12\n",
       "2     5\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38\n",
      "[[5 4 2 5]\n",
      " [3 1 1 0]\n",
      " [2 2 5 3]\n",
      " [6 2 1 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.31      0.31        16\n",
      "           2       0.11      0.20      0.14         5\n",
      "           3       0.56      0.42      0.48        12\n",
      "           4       0.50      0.47      0.48        17\n",
      "\n",
      "    accuracy                           0.38        50\n",
      "   macro avg       0.37      0.35      0.35        50\n",
      "weighted avg       0.41      0.38      0.39        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# RandomForestClassifier(100)---default\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=500,random_state=45)\n",
    "rf.fit(X_train,y_train)\n",
    "predrf=rf.predict(X_test)\n",
    "print(accuracy_score(y_test,predrf))\n",
    "print(confusion_matrix(y_test,predrf))\n",
    "print(classification_report(y_test,predrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36\n",
      "[[5 4 2 5]\n",
      " [3 1 1 0]\n",
      " [2 2 5 3]\n",
      " [6 3 1 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.31      0.31        16\n",
      "           2       0.10      0.20      0.13         5\n",
      "           3       0.56      0.42      0.48        12\n",
      "           4       0.47      0.41      0.44        17\n",
      "\n",
      "    accuracy                           0.36        50\n",
      "   macro avg       0.36      0.34      0.34        50\n",
      "weighted avg       0.40      0.36      0.38        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# AdaBoostClassifier(base_estimator=DecisionTreeclassifier(),n_estimators=50,learning_rate=1.0)\n",
    "\n",
    "ad=AdaBoostClassifier()\n",
    "ad.fit(X_train,y_train)\n",
    "ad_pred=ad.predict(X_test)\n",
    "print(accuracy_score(y_test,predrf))\n",
    "print(confusion_matrix(y_test,predrf))\n",
    "print(classification_report(y_test,predrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34\n",
      "[[ 0  0  0 16]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 12]\n",
      " [ 0  0  0 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       0.34      1.00      0.51        17\n",
      "\n",
      "    accuracy                           0.34        50\n",
      "   macro avg       0.09      0.25      0.13        50\n",
      "weighted avg       0.12      0.34      0.17        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import support vector classifier\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "\n",
    "#create  adaboost classifier object\n",
    "ad=AdaBoostClassifier(n_estimators=50, base_estimator=svc,algorithm='SAMME')\n",
    "ad.fit(X_train,y_train)\n",
    "\n",
    "ad_pred=ad.predict(X_test)\n",
    "print(accuracy_score(y_test,ad_pred))\n",
    "print(confusion_matrix(y_test,ad_pred))\n",
    "print(classification_report(y_test,ad_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34\n",
      "[[ 0  0  0 16]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 12]\n",
      " [ 0  0  0 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       0.34      1.00      0.51        17\n",
      "\n",
      "    accuracy                           0.34        50\n",
      "   macro avg       0.09      0.25      0.13        50\n",
      "weighted avg       0.12      0.34      0.17        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(probability=True, kernel='linear')\n",
    "\n",
    "# create  adaboost classifier object\n",
    "ad=AdaBoostClassifier(n_estimators=50, base_estimator=svc)\n",
    "ad.fit(X_train,y_train)\n",
    "ad_pred=ad.predict(X_test)\n",
    "print(accuracy_score(y_test,ad_pred))\n",
    "print(confusion_matrix(y_test,ad_pred))\n",
    "print(classification_report(y_test,ad_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36\n",
      "[[4 4 4 4]\n",
      " [2 1 1 1]\n",
      " [1 3 5 3]\n",
      " [7 2 0 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.25      0.27        16\n",
      "           2       0.10      0.20      0.13         5\n",
      "           3       0.50      0.42      0.45        12\n",
      "           4       0.50      0.47      0.48        17\n",
      "\n",
      "    accuracy                           0.36        50\n",
      "   macro avg       0.35      0.33      0.33        50\n",
      "weighted avg       0.39      0.36      0.37        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb=GradientBoostingClassifier()\n",
    "gb.fit(X_train,y_train)\n",
    "gb_pred=gb.predict(X_test)\n",
    "print(accuracy_score(y_test,gb_pred))\n",
    "print(confusion_matrix(y_test,gb_pred))\n",
    "print(classification_report(y_test,gb_pred))\n",
    "\n",
    "# check score for all above esembled model & save anyone using joblib or pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# From sklearn matrics import accuracy_score,confusion_matrix,classification_reports\n",
    "# Cross validation Libraries\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n",
      "[[ 7  1  4  4]\n",
      " [ 2  0  1  2]\n",
      " [ 3  1  3  5]\n",
      " [ 2  2  2 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.44      0.47        16\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.30      0.25      0.27        12\n",
      "           4       0.50      0.65      0.56        17\n",
      "\n",
      "    accuracy                           0.42        50\n",
      "   macro avg       0.33      0.33      0.33        50\n",
      "weighted avg       0.40      0.42      0.41        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier(criterion='gini')---->default\n",
    "# DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(X_train,y_train)\n",
    "dtc.score(X_train,y_train)\n",
    "preddtc=dtc.predict(X_test)\n",
    "print(accuracy_score(y_test,preddtc))\n",
    "print(confusion_matrix(y_test,preddtc))\n",
    "print(classification_report(y_test,preddtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.485, 3.205, 1.88 , 2.405, 2.44 , 3.54 , 2.855, 2.485, 2.935,\n",
       "       3.19 , 1.8  , 1.56 , 1.92 , 3.1  , 3.86 , 2.135, 2.43 , 2.325,\n",
       "       3.415, 1.665, 3.24 , 3.035, 2.75 , 3.73 , 2.3  , 2.75 , 2.81 ,\n",
       "       2.12 , 2.295, 2.245, 2.755, 2.665, 1.625, 1.905, 2.335, 3.505,\n",
       "       3.18 , 2.32 , 3.455, 1.385, 2.9  , 2.41 , 1.685, 1.78 , 2.255,\n",
       "       1.73 , 2.14 , 2.855, 3.31 , 3.135])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf=RandomForestRegressor(n_estimators=200,random_state=45)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "rf.score(X_train,y_train)\n",
    "\n",
    "pred=rf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: [0.57142857 0.14285714 0.28571429 0.42857143 0.42857143 0.42857143\n",
      " 0.71428571 0.57142857 0.28571429 0.57142857 0.42857143 0.14285714\n",
      " 0.71428571 0.28571429 0.         0.28571429 0.28571429 0.28571429\n",
      " 0.         0.28571429 0.16666667 0.16666667 0.16666667 0.\n",
      " 0.         0.16666667 0.16666667 0.33333333 0.         0.16666667]\n",
      "mean score: 0.28253968253968254\n",
      "stn deviation: 0.20247274606715543\n",
      "Y prediction values\n",
      "[1 4 1 1 4 1 1 2 1 1 4 1 2 1 4 1 4 1 1 1 1 1 4 4 1 1 3 3 1 2 2 3 1 2 3 2 1\n",
      " 1 2 4 4 4 2 4 2 2 1 3 4 1 1 4 1 1 1 2 2 1 4 1 4 2 2 2 2 2 3 1 4 4 1 1 4 2\n",
      " 2 1 2 4 2 1 2 3 2 2 1 1 3 4 2 4 4 1 2 3 4 1 4 4 2 2 1 1 2 1 1 1 4 3 3 1 3\n",
      " 1 4 4 3 1 2 3 1 4 4 3 1 4 2 4 3 1 2 3 4 1 2 2 4 2 4 4 3 4 4 3 4 4 1 2 1 4\n",
      " 3 1 1 1 3 2 4 3 1 1 4 2 2 3 2 2 3 1 1 2 1 2 2 1 2 2 4 2 3 1 3 1 3 3 1 2 1\n",
      " 3 1 1 4 2 3 2 4 2 1 3 2 1 3 1]\n",
      "y_pred.shape (200,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[20, 15, 10, 11],\n",
       "       [18, 11,  5,  7],\n",
       "       [14, 11,  8,  9],\n",
       "       [18, 15,  9, 19]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "score=cross_val_score(knn,X,y,cv=30,scoring='accuracy')\n",
    "\n",
    "print('accuracy score:',score)\n",
    "print('mean score:',score.mean())\n",
    "print('stn deviation:',score.std())\n",
    "\n",
    "y_pred = cross_val_predict(knn, X, y, cv=30)\n",
    "\n",
    "print('Y prediction values')\n",
    "print(y_pred)\n",
    "\n",
    "print(\"y_pred.shape\",y_pred.shape)\n",
    "\n",
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score for Random Forest Classifier: 38.00 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib_file = \"joblib_rf.pkl\"             # Save to file in the current working directory\n",
    "joblib.dump(rf, joblib_file)\n",
    "joblib_rf = joblib.load(joblib_file)      # Load from file\n",
    "score = joblib_rf.score(X_test, y_test)   # Calculate the accuracy and predictions\n",
    "print(\"Test score for Random Forest Classifier: {0:.2f} %\".format(100 * score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - After applying all logistical model & regressor,booster,ensemble technique,final score getting as 38%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
